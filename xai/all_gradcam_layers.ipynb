{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:24:28.248648600Z",
     "start_time": "2026-02-09T17:24:18.950709700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 18:24:28,230 - logger - INFO - Logger initialized\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from matplotlib.colors import ListedColormap\n",
    "from nibabel.processing import resample_from_to\n",
    "import scipy.ndimage as ndi\n",
    "import config.config as cf\n",
    "from utilities.patient_files import get_center_patient\n",
    "import torch\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib import gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "patient_id = 51\n",
    "center, patient = get_center_patient(patient_id)\n",
    "center_patient = f\"{center}_{patient}\"\n",
    "dataset_id = 201\n",
    "\n",
    "a = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/decoder.stages.0/attention_map_0_0_0.nii.gz\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:25:53.577954Z",
     "start_time": "2026-02-09T17:25:53.528532300Z"
    }
   },
   "id": "f93bf03a2a7363c0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "layers = ['decoder', 'decoder.stages.0', 'decoder.stages.1', 'decoder.stages.2', 'decoder.stages.3', 'decoder.stages.4', 'decoder.transpconvs.0', 'decoder.transpconvs.1', 'decoder.transpconvs.2', 'decoder.transpconvs.3', 'decoder.transpconvs.4', 'decoder.seg_layers.4']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:25:55.408234Z",
     "start_time": "2026-02-09T17:25:55.392784600Z"
    }
   },
   "id": "99a9bd569fa80d2e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def windows_to_wsl_path(win_path: str) -> str:\n",
    "    p = Path(win_path).resolve()\n",
    "    drive = p.drive[0].lower()  # 'C:' -> 'c'\n",
    "    rest = p.parts[1:]  # skip the 'C:\\'\n",
    "    return f\"/mnt/{drive}/\" + \"/\".join(rest)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-05T10:44:35.416715200Z",
     "start_time": "2025-09-05T10:44:35.400306600Z"
    }
   },
   "id": "773a63fccf2caae5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'windows_to_wsl_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 13\u001B[39m\n\u001B[32m      9\u001B[39m cam_resampled = resample_from_to(cam_img, nib.load(flair))\n\u001B[32m     10\u001B[39m \u001B[38;5;66;03m#nib.save(cam_resampled, output_reorient)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m cmd_str = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mflirt -in \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mwindows_to_wsl_path\u001B[49m(output_reorient)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m -ref \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwindows_to_wsl_path(flair)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m -out \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwindows_to_wsl_path(output)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m -dof 6 -interp trilinear\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     14\u001B[39m cmd = [\u001B[33m\"\u001B[39m\u001B[33mwsl\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mbash\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m-ic\u001B[39m\u001B[33m\"\u001B[39m, cmd_str] \n\u001B[32m     15\u001B[39m result = subprocess.run(cmd, capture_output=\u001B[38;5;28;01mTrue\u001B[39;00m, text=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mNameError\u001B[39m: name 'windows_to_wsl_path' is not defined"
     ]
    }
   ],
   "source": [
    "input = f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/decoder/attention_map_0_0_0.nii.gz\"\n",
    "output = f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/decoder/attention_map_0_0_0_registered.nii.gz\"\n",
    "flair = rf\"{cf.nnUNet_raw}\\{cf.dataset_201}\\imagesTs\\\\Patient-{patient_id}_0004.nii.gz\"\n",
    "\n",
    "output_reorient = f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/decoder/attention_map_0_0_0_reoriented.nii.gz\"\n",
    "\n",
    "cam_img = nib.as_closest_canonical(nib.load(input))\n",
    "nib.save(cam_img, output_reorient)\n",
    "cam_resampled = resample_from_to(cam_img, nib.load(flair))\n",
    "#nib.save(cam_resampled, output_reorient)\n",
    "\n",
    "\n",
    "cmd_str = f\"flirt -in '{windows_to_wsl_path(output_reorient)}' -ref '{windows_to_wsl_path(flair)}' -out '{windows_to_wsl_path(output)}' -dof 6 -interp trilinear\"\n",
    "cmd = [\"wsl\", \"bash\", \"-ic\", cmd_str] \n",
    "result = subprocess.run(cmd, capture_output=True, text=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-22T16:40:15.128909800Z",
     "start_time": "2025-10-22T16:40:12.710838Z"
    }
   },
   "id": "f1bd24fef7ee66cb"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7d646a2054cc51c6"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "flair = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_{dataset_id}/flair.nii.gz\")\n",
    "flair_img = flair.get_fdata()\n",
    "layers = ['decoder.stages.0', 'decoder.stages.1', 'decoder.stages.2', 'decoder.stages.3', 'decoder.stages.4', 'decoder.seg_layers.4']\n",
    "for layer in layers:\n",
    "    input = f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/{layer}/attention_map_0_0_0.nii.gz\"\n",
    "    output = f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/{layer}/attention_map_0_0_0_registered.nii.gz\"\n",
    "    \n",
    "    cam_data_correct = np.transpose(nib.load(input).get_fdata(), (2,0,1))\n",
    "    heatmap = nib.Nifti1Image(cam_data_correct.astype(np.float32), flair.affine)\n",
    "    nib.save(heatmap, output)\n",
    "    \n",
    "    if heatmap.shape != flair_img.shape:\n",
    "        zoom_factors = np.array(flair_img.shape) / np.array(heatmap.shape)\n",
    "        cam_up = ndi.zoom(heatmap.get_fdata() , zoom=zoom_factors, order=1)\n",
    "        \n",
    "        cam_up_img = nib.Nifti1Image(cam_up, flair.affine, flair.header)\n",
    "        nib.save(cam_up_img, f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/{layer}/attention_map_0_0_0_resampled.nii.gz\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:26:41.558060100Z",
     "start_time": "2026-02-09T17:26:36.454917200Z"
    }
   },
   "id": "f71afec76fe8139"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def compute_mean_heatmap(heatmaps):\n",
    "    return np.mean(heatmaps, axis=0)\n",
    "\n",
    "def relevance_window(mean_heatmap, top_fraction=0.5, bins=200):\n",
    "    values = mean_heatmap.flatten()\n",
    "    \n",
    "    hist, bin_edges = np.histogram(values, bins=bins)\n",
    "    \n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    relevance_per_bin = hist * bin_centers\n",
    "    \n",
    "    total_relevance = np.sum(relevance_per_bin)\n",
    "    cumulative = np.cumsum(relevance_per_bin[::-1])  # start from high relevance\n",
    "    cutoff_idx = np.where(cumulative >= top_fraction * total_relevance)[0][0]\n",
    "    \n",
    "    lower_value = bin_edges[::-1][cutoff_idx]\n",
    "    \n",
    "    windowed = np.copy(mean_heatmap)\n",
    "    windowed[windowed < lower_value] = 0\n",
    "    \n",
    "    return windowed, lower_value\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:26:25.962431500Z",
     "start_time": "2026-02-09T17:26:25.959917600Z"
    }
   },
   "id": "96269b08062427d0"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "patient_id = 48\n",
    "patient, center = get_center_patient(patient_id)\n",
    "center_patient = f\"{patient}_{center}\"\n",
    "dataset_id = 201\n",
    "\n",
    "gt = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_{dataset_id}_new_orient/gt.nii.gz\").get_fdata()\n",
    "gt = torch.tensor(gt).squeeze(0)\n",
    "flair = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_{dataset_id}_new_orient/flair.nii.gz\").get_fdata()\n",
    "flair_nii = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_{dataset_id}_new_orient/flair.nii.gz\")\n",
    "prediction = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_{dataset_id}_new_orient/prediction.nii.gz\").get_fdata()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:45:29.882288100Z",
     "start_time": "2026-02-09T17:45:29.593953600Z"
    }
   },
   "id": "bdf9b243c21ff6b8"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 128)\n",
      "(256, 128)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib qt\n",
    "\n",
    "gradcam_stages0 = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/decoder.stages.0/attention_map_0_0_0_resampled.nii.gz\").get_fdata()\n",
    "gradcam_stages1 = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/decoder.stages.1/attention_map_0_0_0_resampled.nii.gz\").get_fdata()\n",
    "gradcam_stages2 = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/decoder.stages.2/attention_map_0_0_0_resampled.nii.gz\").get_fdata()\n",
    "gradcam_stages3 = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/decoder.stages.3/attention_map_0_0_0_resampled.nii.gz\").get_fdata()\n",
    "gradcam_stages4 = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/decoder.stages.4/attention_map_0_0_0_registered.nii.gz\").get_fdata()\n",
    "gradcam_seglayers = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/decoder.seg_layers.4/attention_map_0_0_0_registered.nii.gz\").get_fdata()\n",
    "\n",
    "gradcams = [gradcam_stages3,gradcam_stages4, gradcam_seglayers]\n",
    "\n",
    "vmin = 0\n",
    "vmax = np.max([np.max(gc) for gc in gradcams])\n",
    "\n",
    "mean_heatmap = compute_mean_heatmap(gradcams)\n",
    "windowed, thr = relevance_window(mean_heatmap, top_fraction=0.5)\n",
    "\n",
    "plt.rcParams.update({     \n",
    "    \"font.size\": 16,        \n",
    "    \"axes.titlesize\": 16, \n",
    "    \"axes.labelsize\": 16,   \n",
    "    \"legend.fontsize\": 16   \n",
    "})\n",
    "\n",
    "zooms = flair_nii.header.get_zooms()\n",
    "\n",
    "\n",
    "def plot_attention_on_image(axs, flair_slice, gt_slice, mask_slice, gradcam_slices, alpha=1):\n",
    "    masked = flair_slice.copy()\n",
    "    eps = 1e-5\n",
    "    masked[np.abs(masked) < eps] = np.min(flair_slice)\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for im in axs[i,j].images:\n",
    "                im.remove()        \n",
    "    extent = [0, flair_slice.shape[0] * zooms[2], 0, flair_slice.shape[1] * zooms[0]]\n",
    "    axs[0,0].imshow(masked, cmap='gray', origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "    axs[0,0].set_title('FLAIR'); axs[0,0].axis('off')\n",
    "\n",
    "    lesion_cmap_gt = ListedColormap([[0,0,0,0], [1,0,0,alpha]])\n",
    "    gt_bin = (gt_slice == 1).astype(int)\n",
    "    axs[0,1].imshow(masked, cmap='gray', origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "    axs[0,1].imshow(gt_bin, cmap=lesion_cmap_gt, origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "    axs[0,1].set_title('FLAIR + GT'); axs[0,1].axis('off')\n",
    "\n",
    "    lesion_cmap_pred = ListedColormap([[0,0,0,0], [0,0,1,alpha]])\n",
    "    mask_bin = (mask_slice == 1).astype(int)\n",
    "    axs[0,2].imshow(masked, cmap='gray', origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "    axs[0,2].imshow(mask_bin, cmap=lesion_cmap_pred, origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "    axs[0,2].set_title('FLAIR + Prediction'); axs[0,2].axis('off')\n",
    "\n",
    "    titles = ['stages.0', r'$\\mathbf{Grad-CAMs\\ of\\ decoder\\ layers}$' + '\\n' + 'stages.1', 'stages.2',\n",
    "              'stages.3', 'stages.4', 'seg_layers.4']\n",
    "    positions = [(1,0),(1,1),(1,2),(2,0),(2,1),(2,2)]\n",
    "    ims = []\n",
    "    \n",
    "    for gc, title, pos in zip(gradcam_slices, titles, positions):\n",
    "        gc_masked = np.where(gc >= thr, gc, np.nan)\n",
    "\n",
    "        axs[pos].imshow(masked, cmap='gray', origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "        #if pos >= (2,0):\n",
    "        im = axs[pos].imshow(gc_masked, cmap='jet', alpha=alpha, vmax=vmax, origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "        #im = axs[pos].imshow(gc_masked, cmap='jet', alpha=alpha, vmax=vmax)\n",
    "        #else:\n",
    "        #    im = axs[pos].imshow(gc_masked, cmap='jet', alpha=alpha)\n",
    "        axs[pos].set_title(title)\n",
    "        axs[pos].axis('off')\n",
    "        ims.append(im)\n",
    "\n",
    "    return ims\n",
    "\n",
    "class SliceViewer:\n",
    "    def __init__(self, image,gt, prediction,  gradcam_stages0, gradcam_stages1, gradcam_stages2, gradcam_stages3, gradcam_stages4,  gradcam_seglayers):\n",
    "        self.image = image\n",
    "        self.prediction = prediction\n",
    "        self.gt = gt\n",
    "        self.gradcams = [gradcam_stages0, gradcam_stages1, gradcam_stages2,\n",
    "                         gradcam_stages3, gradcam_stages4, gradcam_seglayers]\n",
    "        \n",
    "        self.slice = 128# image.shape[2] // 2\n",
    "        \n",
    "        \n",
    "        self.fig, self.axs = plt.subplots(3, 3,  figsize=(20,10), constrained_layout=False)\n",
    "        \n",
    "        self.fig.set_constrained_layout_pads(w_pad=10.05, h_pad=10.05, hspace=10.05, wspace=10.05)\n",
    "        plt.subplots_adjust(hspace=0.4) \n",
    "                \n",
    "        gs = gridspec.GridSpec(3, 4, width_ratios=[1,1,1,0.05], figure=self.fig)\n",
    "        self.cax = self.fig.add_subplot(gs[1:,3])\n",
    "        self.colorbars = []\n",
    "        \n",
    "        self.update()\n",
    "        self.fig.canvas.mpl_connect(\"scroll_event\", self.on_scroll)\n",
    "        self.fig.canvas.mpl_connect(\"key_press_event\", self.on_key)\n",
    "\n",
    "    def get_slices(self, idx):\n",
    "        k=3\n",
    "        flair = np.rot90(self.image[:,idx,:], k=k)\n",
    "        gt_slice = np.rot90(self.gt[:,idx,:], k=k)\n",
    "        mask_slice = np.rot90(self.prediction[:,idx,:], k=k)\n",
    "        gradcam_slices = [np.rot90(gc[:, idx, :], k=k) for gc in self.gradcams]\n",
    "    \n",
    "        return flair, gt_slice, mask_slice, gradcam_slices\n",
    "\n",
    "    def update(self):\n",
    "        flair, gt_slice, mask_slice, gradcam_slices = self.get_slices(self.slice)\n",
    "        ims = plot_attention_on_image(self.axs, flair, gt_slice, mask_slice, gradcam_slices)\n",
    "        \n",
    "        if not self.colorbars:\n",
    "            cbar = self.fig.colorbar(ims[-1], cax=self.cax, orientation=\"vertical\")\n",
    "            cbar.set_label(\"Attention Score\")\n",
    "            self.colorbars.append(cbar)\n",
    "        else:\n",
    "            self.colorbars[0].mappable.set_clim(vmin=0, vmax=vmax)\n",
    "    \n",
    "        self.fig.suptitle(f\"Patient {patient} of Centre {center} | Slice {self.slice}/{self.image.shape[1]-1}\", fontsize=16)\n",
    "        for ax in self.axs.flatten():\n",
    "            ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "            ax.axis(\"off\")\n",
    "    \n",
    "        self.fig.canvas.draw_idle()\n",
    "        self.fig.canvas.flush_events()\n",
    "\n",
    "    def on_scroll(self, event):\n",
    "        if event.button == 'up':\n",
    "            self.slice = (self.slice + 1) % self.image.shape[2]\n",
    "        elif event.button == 'down':\n",
    "            self.slice = (self.slice - 1) % self.image.shape[2]\n",
    "        self.update()\n",
    "\n",
    "    def on_key(self, event):\n",
    "        if event.key == 'right':\n",
    "            self.slice = (self.slice + 1) % self.image.shape[2]\n",
    "        elif event.key == 'left':\n",
    "            self.slice = (self.slice - 1) % self.image.shape[2]\n",
    "        self.update()\n",
    "\n",
    "\n",
    "viewer = SliceViewer(flair, gt, prediction,  gradcam_stages0, gradcam_stages1, gradcam_stages2, gradcam_stages3, gradcam_stages4,  gradcam_seglayers)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:46:25.149728600Z",
     "start_time": "2026-02-09T17:46:23.900518Z"
    }
   },
   "id": "bd51078e3e02708d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "gradcam_stages3 = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/decoder.stages.3/attention_map_0_0_0_resampled.nii.gz\").get_fdata()\n",
    "gradcam_stages4 = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/decoder.stages.4/attention_map_0_0_0_registered.nii.gz\").get_fdata()\n",
    "gradcam_seglayers = nib.load(f\"{cf.plots}/xai/attention_maps_{center_patient}_test_{dataset_id}/gcam/decoder.seg_layers.4/attention_map_0_0_0_registered.nii.gz\").get_fdata()\n",
    "\n",
    "gradcams = [gradcam_stages3,gradcam_stages4, gradcam_seglayers]\n",
    "\n",
    "vmin = 0\n",
    "vmax = np.max([np.max(gc) for gc in gradcams])\n",
    "\n",
    "mean_heatmap = compute_mean_heatmap(gradcams)\n",
    "windowed, thr = relevance_window(mean_heatmap, top_fraction=0.5)\n",
    "\n",
    "plt.rcParams.update({     \n",
    "    \"font.size\": 25,        \n",
    "    \"axes.titlesize\": 25, \n",
    "    \"axes.labelsize\": 25,   \n",
    "    \"legend.fontsize\": 25   \n",
    "})\n",
    "\n",
    "zooms = flair_nii.header.get_zooms()\n",
    "\n",
    "def plot_attention_on_image(axs, flair_slice, gt_slice, mask_slice, gradcam_slices, alpha=1):\n",
    "    masked = flair_slice.copy()\n",
    "    eps = 1e-4\n",
    "    masked[np.abs(masked) < eps] = np.min(flair_slice)\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            for im in axs[i,j].images:\n",
    "                im.remove()\n",
    "                \n",
    "    print(flair_slice.shape)            \n",
    "    print(zooms)            \n",
    "    extent = [0, flair_slice.shape[0] * zooms[2], 0, flair_slice.shape[1] * zooms[0]]\n",
    "    print(extent)\n",
    "    #extent = [0,2,0,3]\n",
    "    axs[0,0].imshow(masked, cmap='gray', origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "    axs[0,0].set_title('FLAIR'); axs[0,0].axis('off')\n",
    "\n",
    "    lesion_cmap_gt = ListedColormap([[0,0,0,0], [1,0,0,alpha]])\n",
    "    gt_bin = (gt_slice == 1).astype(int)\n",
    "    axs[0,1].imshow(masked, cmap='gray', origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "    axs[0,1].imshow(gt_bin, cmap=lesion_cmap_gt, origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "    axs[0,1].set_title('FLAIR + GT'); axs[0,1].axis('off')\n",
    "\n",
    "    lesion_cmap_pred = ListedColormap([[0,0,0,0], [0,0,1,alpha]])\n",
    "    mask_bin = (mask_slice == 1).astype(int)\n",
    "    axs[0,2].imshow(masked, cmap='gray', origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "    axs[0,2].imshow(mask_bin, cmap=lesion_cmap_pred, origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "    axs[0,2].set_title('FLAIR + Prediction'); axs[0,2].axis('off')\n",
    "\n",
    "    titles = ['stages.3', r'$\\mathbf{Grad-CAMs\\ of\\ decoder\\ layers}$' + '\\n' + 'stages.4', 'seg_layers.4']\n",
    "    positions = [(1,0),(1,1),(1,2)]\n",
    "    ims = []\n",
    "    \n",
    "\n",
    "    for gc, title, pos in zip(gradcam_slices, titles, positions):\n",
    "        gc_masked = np.where(gc >= thr, gc, np.nan)\n",
    "\n",
    "        axs[pos].imshow(masked, cmap='gray', origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "        #if pos >= (2,0):\n",
    "        im = axs[pos].imshow(gc_masked, cmap='jet', alpha=alpha, vmax=vmax, origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "        #else:\n",
    "        #    im = axs[pos].imshow(gc_masked, cmap='jet', alpha=alpha)\n",
    "        axs[pos].set_title(title)\n",
    "        axs[pos].axis('off')\n",
    "        ims.append(im)\n",
    "\n",
    "    return ims\n",
    "\n",
    "class SliceViewer:\n",
    "    def __init__(self, image,gt, prediction,  gradcam_stages3, gradcam_stages4,  gradcam_seglayers):\n",
    "        self.image = image\n",
    "        self.prediction = prediction\n",
    "        self.gt = gt\n",
    "        self.gradcams = [gradcam_stages3, gradcam_stages4, gradcam_seglayers]\n",
    "        \n",
    "        self.slice = image.shape[2] // 2\n",
    "        \n",
    "        \n",
    "        self.fig, self.axs = plt.subplots(2, 3,  figsize=(15,10), constrained_layout=True)\n",
    "        \n",
    "        self.fig.set_constrained_layout_pads(w_pad=0.05, h_pad=0.05, hspace=0.05, wspace=0.05)\n",
    "                \n",
    "        gs = gridspec.GridSpec(2, 4, width_ratios=[1,1,1,0.05], figure=self.fig)\n",
    "        self.cax = self.fig.add_subplot(gs[1:,3])\n",
    "        self.colorbars = []\n",
    "        plt.subplots_adjust(wspace=0.4) \n",
    "        self.update()\n",
    "        self.fig.canvas.mpl_connect(\"scroll_event\", self.on_scroll)\n",
    "        self.fig.canvas.mpl_connect(\"key_press_event\", self.on_key)\n",
    "\n",
    "    def get_slices(self, idx):\n",
    "        k=3\n",
    "        flair = np.rot90(self.image[:,idx,:], k=k)\n",
    "        gt_slice = np.rot90(self.gt[:,idx,:], k=k)\n",
    "        mask_slice = np.rot90(self.prediction[:,idx,:], k=k)\n",
    "        gradcam_slices = [np.rot90(gc[:, idx, :], k=k) for gc in self.gradcams]\n",
    "    \n",
    "    \n",
    "        return flair, gt_slice, mask_slice, gradcam_slices\n",
    "\n",
    "    def update(self):\n",
    "        # Neue Slices holen\n",
    "        flair, gt_slice, mask_slice, gradcam_slices = self.get_slices(self.slice)\n",
    "        ims = plot_attention_on_image(self.axs, flair, gt_slice, mask_slice, gradcam_slices)\n",
    "        \n",
    "        self.fig.suptitle(f\"Patient {patient} of Centre {center} | Slice {self.slice}/{self.image.shape[1]-1}\", fontsize=25)\n",
    "        \n",
    "        # Colorbar nur beim ersten Mal erstellen\n",
    "        if not self.colorbars:\n",
    "            cbar = self.fig.colorbar(ims[-1], cax=self.cax, orientation=\"vertical\")\n",
    "            cbar.set_label(\"Attention Score\")\n",
    "            self.colorbars.append(cbar)\n",
    "        else:\n",
    "            # Nur Wertebereich aktualisieren\n",
    "            self.colorbars[0].mappable.set_clim(vmin=0,\n",
    "                                                vmax=vmax)\n",
    "    \n",
    "        for ax in self.axs.flatten():\n",
    "            ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "            ax.axis(\"off\")\n",
    "    \n",
    "        # Erzwingt Redraw\n",
    "        self.fig.canvas.draw_idle()\n",
    "        self.fig.canvas.flush_events()\n",
    "\n",
    "\n",
    "\n",
    "    def on_scroll(self, event):\n",
    "        if event.button == 'up':\n",
    "            self.slice = (self.slice + 1) % self.image.shape[2]\n",
    "        elif event.button == 'down':\n",
    "            self.slice = (self.slice - 1) % self.image.shape[2]\n",
    "        self.update()\n",
    "\n",
    "    def on_key(self, event):\n",
    "        if event.key == 'right':\n",
    "            self.slice = (self.slice + 1) % self.image.shape[2]\n",
    "        elif event.key == 'left':\n",
    "            self.slice = (self.slice - 1) % self.image.shape[2]\n",
    "        self.update()\n",
    "\n",
    "\n",
    "viewer = SliceViewer(flair, gt, prediction, gradcam_stages3, gradcam_stages4,  gradcam_seglayers)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19ff40fd6fa6b778"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "af39ef806b87741"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
